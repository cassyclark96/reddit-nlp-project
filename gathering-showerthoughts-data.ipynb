{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Posts From the Subreddit ShowerThoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import usefull libraries\n",
    "import pandas as pd   \n",
    "import requests  \n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "\n",
    "- In this notebook I will be gathering data from the ShowerThoughts subreddit by ushing the pushshift API.\n",
    "- Since we are limited to 100 pulls per call, a function will be needed with a timer set to 30 seconds so that I don't get kicked out of the pushshift API.\n",
    "- The posts will be added to a dataframe containing the title and text of post and then saved to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty list for posts\n",
    "posts = []\n",
    "\n",
    "#create an empty list to keep track of post times so we don't get duplicates\n",
    "skip = [1600460524]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_pulls(subreddit):\n",
    "    #count to keep track of how many posts we've pulled\n",
    "    count = 0\n",
    "    \n",
    "    #since we are doing 100 pulls at a time, we can stop once the count hits 90\n",
    "    while count < 90:\n",
    "        \n",
    "        #set up search paramters for requests\n",
    "        pull_params = {'subreddit': subreddit,\n",
    "                       'size': 100,\n",
    "                       'sort': 'desc',\n",
    "                       'aggs': 'created_utc',\n",
    "                       'before': skip[-1]}\n",
    "        \n",
    "        #create url\n",
    "        url = f'https://api.pushshift.io/reddit/submission/search/'\n",
    "        \n",
    "        #get requests\n",
    "        res = requests.get(url, params=pull_params)\n",
    "    \n",
    "        #turn into json dictionary format\n",
    "        data = res.json()\n",
    "              \n",
    "        #add pulls to post list\n",
    "        posts.extend(data['data'])\n",
    "    \n",
    "        #add count\n",
    "        count += 1\n",
    "        \n",
    "        #create dataframe for post list\n",
    "        shower_data = pd.DataFrame(posts)[['author', 'title', 'subreddit', 'created_utc']]\n",
    "\n",
    "        #save data frame as csv to be called back in to update\n",
    "        shower_data.to_csv('./data/shower_data.csv', index=False)\n",
    "        \n",
    "        #create data frame to hold new posts\n",
    "        post_data = pd.DataFrame(posts)[['author', 'title', 'subreddit', 'created_utc']]\n",
    "        \n",
    "        #merge two data frames together\n",
    "        frames = [shower_data, post_data]\n",
    "        result = pd.concat(frames)\n",
    "        result = result.drop_duplicates(subset='title')\n",
    "        \n",
    "        #save updated shower_data file\n",
    "        result.to_csv('./data/shower_data.csv', index=False)\n",
    "        \n",
    "        #get the last pulls time tag and append to \n",
    "        skip.append(result['created_utc'].min())\n",
    "            \n",
    "        print(f'This is pull {count} out of 90')\n",
    "    \n",
    "        #set sleep timer for 30 seconds so I don't get banned\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is pull 1 out of 90\n",
      "This is pull 2 out of 90\n",
      "This is pull 3 out of 90\n",
      "This is pull 4 out of 90\n",
      "This is pull 5 out of 90\n",
      "This is pull 6 out of 90\n",
      "This is pull 7 out of 90\n",
      "This is pull 8 out of 90\n",
      "This is pull 9 out of 90\n",
      "This is pull 10 out of 90\n",
      "This is pull 11 out of 90\n",
      "This is pull 12 out of 90\n",
      "This is pull 13 out of 90\n",
      "This is pull 14 out of 90\n",
      "This is pull 15 out of 90\n",
      "This is pull 16 out of 90\n",
      "This is pull 17 out of 90\n",
      "This is pull 18 out of 90\n",
      "This is pull 19 out of 90\n",
      "This is pull 20 out of 90\n",
      "This is pull 21 out of 90\n",
      "This is pull 22 out of 90\n",
      "This is pull 23 out of 90\n",
      "This is pull 24 out of 90\n",
      "This is pull 25 out of 90\n",
      "This is pull 26 out of 90\n",
      "This is pull 27 out of 90\n",
      "This is pull 28 out of 90\n",
      "This is pull 29 out of 90\n",
      "This is pull 30 out of 90\n",
      "This is pull 31 out of 90\n",
      "This is pull 32 out of 90\n",
      "This is pull 33 out of 90\n",
      "This is pull 34 out of 90\n",
      "This is pull 35 out of 90\n",
      "This is pull 36 out of 90\n",
      "This is pull 37 out of 90\n",
      "This is pull 38 out of 90\n",
      "This is pull 39 out of 90\n",
      "This is pull 40 out of 90\n",
      "This is pull 41 out of 90\n",
      "This is pull 42 out of 90\n",
      "This is pull 43 out of 90\n",
      "This is pull 44 out of 90\n",
      "This is pull 45 out of 90\n",
      "This is pull 46 out of 90\n",
      "This is pull 47 out of 90\n",
      "This is pull 48 out of 90\n",
      "This is pull 49 out of 90\n",
      "This is pull 50 out of 90\n",
      "This is pull 51 out of 90\n",
      "This is pull 52 out of 90\n",
      "This is pull 53 out of 90\n",
      "This is pull 54 out of 90\n",
      "This is pull 55 out of 90\n",
      "This is pull 56 out of 90\n",
      "This is pull 57 out of 90\n",
      "This is pull 58 out of 90\n",
      "This is pull 59 out of 90\n",
      "This is pull 60 out of 90\n",
      "This is pull 61 out of 90\n",
      "This is pull 62 out of 90\n",
      "This is pull 63 out of 90\n",
      "This is pull 64 out of 90\n",
      "This is pull 65 out of 90\n",
      "This is pull 66 out of 90\n",
      "This is pull 67 out of 90\n",
      "This is pull 68 out of 90\n",
      "This is pull 69 out of 90\n",
      "This is pull 70 out of 90\n",
      "This is pull 71 out of 90\n",
      "This is pull 72 out of 90\n",
      "This is pull 73 out of 90\n",
      "This is pull 74 out of 90\n",
      "This is pull 75 out of 90\n",
      "This is pull 76 out of 90\n",
      "This is pull 77 out of 90\n",
      "This is pull 78 out of 90\n",
      "This is pull 79 out of 90\n",
      "This is pull 80 out of 90\n",
      "This is pull 81 out of 90\n",
      "This is pull 82 out of 90\n",
      "This is pull 83 out of 90\n",
      "This is pull 84 out of 90\n",
      "This is pull 85 out of 90\n",
      "This is pull 86 out of 90\n",
      "This is pull 87 out of 90\n",
      "This is pull 88 out of 90\n",
      "This is pull 89 out of 90\n",
      "This is pull 90 out of 90\n"
     ]
    }
   ],
   "source": [
    "post_pulls('Showerthoughts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call in data frame to make sure it saved correctly\n",
    "shower_data = pd.read_csv('./data/shower_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dadobis</td>\n",
       "      <td>There were probably a lot of singers talented ...</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>1600460465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SueMe-YouWont</td>\n",
       "      <td>Sometimes I really miss college, then I get ou...</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>1600460451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JohnBrambleberry</td>\n",
       "      <td>Someone, at some point, gave the first blowjob...</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>1600460424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jdmlover2009</td>\n",
       "      <td>A.BðŸ’¿.E.F.G</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>1600460371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0Iriss0</td>\n",
       "      <td>The first person to find a cat must have been ...</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>1600460368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8851</th>\n",
       "      <td>ArSeeFurtyFree</td>\n",
       "      <td>We think about aliens as being hugely advanced...</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>1600106046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8852</th>\n",
       "      <td>Tanjarts</td>\n",
       "      <td>We will either find intelligent life, or forev...</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>1600106042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8853</th>\n",
       "      <td>Lum1nar</td>\n",
       "      <td>A trillion years ago a plant died and now itâ€™s...</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>1600106019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8854</th>\n",
       "      <td>Lum1nar</td>\n",
       "      <td>A kazillion years ago a plant died and now itâ€™...</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>1600105982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8855</th>\n",
       "      <td>TDS_PARTY</td>\n",
       "      <td>Candy stores are the most segregated places in...</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>1600105953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8856 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                author                                              title  \\\n",
       "0              dadobis  There were probably a lot of singers talented ...   \n",
       "1        SueMe-YouWont  Sometimes I really miss college, then I get ou...   \n",
       "2     JohnBrambleberry  Someone, at some point, gave the first blowjob...   \n",
       "3         jdmlover2009                                         A.BðŸ’¿.E.F.G   \n",
       "4              0Iriss0  The first person to find a cat must have been ...   \n",
       "...                ...                                                ...   \n",
       "8851    ArSeeFurtyFree  We think about aliens as being hugely advanced...   \n",
       "8852          Tanjarts  We will either find intelligent life, or forev...   \n",
       "8853           Lum1nar  A trillion years ago a plant died and now itâ€™s...   \n",
       "8854           Lum1nar  A kazillion years ago a plant died and now itâ€™...   \n",
       "8855         TDS_PARTY  Candy stores are the most segregated places in...   \n",
       "\n",
       "           subreddit  created_utc  \n",
       "0     Showerthoughts   1600460465  \n",
       "1     Showerthoughts   1600460451  \n",
       "2     Showerthoughts   1600460424  \n",
       "3     Showerthoughts   1600460371  \n",
       "4     Showerthoughts   1600460368  \n",
       "...              ...          ...  \n",
       "8851  Showerthoughts   1600106046  \n",
       "8852  Showerthoughts   1600106042  \n",
       "8853  Showerthoughts   1600106019  \n",
       "8854  Showerthoughts   1600105982  \n",
       "8855  Showerthoughts   1600105953  \n",
       "\n",
       "[8856 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shower_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shower_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
